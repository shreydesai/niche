{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "from nltk.corpus import brown\n",
    "from nltk.classify import accuracy\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import NuSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "PARENT = '/Users/shreydesai/GitHub/niche'\n",
    "CATEGORIES = ['entertainment', 'sports', 'fun', 'games', \n",
    "              'weather', 'science', 'technology', 'politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fileids(category):\n",
    "    \"\"\"Get file IDs of tweets for specified category\"\"\"\n",
    "    path = os.path.join(PARENT, 'corpus', 'processed', category)\n",
    "    return os.listdir(path)\n",
    "\n",
    "def sents(file):\n",
    "    \"\"\"Get list of sentences from a document\"\"\"\n",
    "    f = open(file, 'r', encoding='ISO-8859-1').read().strip()\n",
    "    return [sent.strip() for sent in f.split('\\n')]\n",
    "\n",
    "def words(file):\n",
    "    \"\"\"Get list of words from a document\"\"\"\n",
    "    f = open(file, 'r', encoding='ISO-8859-1').read().strip()\n",
    "    sents = [sent.split(' ') for sent in f.split('\\n')]\n",
    "    words = [word for sent in sents for word in sent if len(word) > 0]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# train tagge\n",
    "brown_tagged_sents = brown.tagged_sents()\n",
    "tagger = nltk.UnigramTagger(brown_tagged_sents, backoff=nltk.DefaultTagger('NN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PS', 'NN'), ('NN', 'OO'), ('OO', 'NN')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff = ['PS', 'NN', 'OO', 'NN']\n",
    "tags = nltk.bigrams(stuff)\n",
    "list(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documents, total_words = [], []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    for fileid in fileids(category):\n",
    "        if fileid == '.DS_Store':\n",
    "            continue\n",
    "        path = os.path.join(PARENT, 'corpus', 'processed',\n",
    "                            category, fileid)\n",
    "        \n",
    "        doc_tags = []\n",
    "        for sent in sents(path):\n",
    "            #tags = ['{}_{}'.format(x,y) for (x,y) in tagger.tag(sent.split(' '))]\n",
    "            tags = [y for (x,y) in tagger.tag(sent.split(' '))]\n",
    "            #tags = list(nltk.bigrams(tags))\n",
    "            doc_tags.extend(tags)\n",
    "            total_words.extend(tags)\n",
    "        documents.append((doc_tags, category))\n",
    "\n",
    "print('POS tag count:', len(total_words))\n",
    "print(total_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def features(document):\n",
    "    \"\"\"Builds list of features for each document\"\"\"\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def bigram_features(words, score_fn=BigramAssocMeasures.chi_sq, n=2000):\n",
    "    \"\"\"Builds bigram features from document\"\"\"\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return {bigram: True for bigram in bigrams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print('Building vocab')\n",
    "vocab = set(total_words)\n",
    "word_features = list(vocab)\n",
    "random.shuffle(word_features)\n",
    "word_features = word_features[:2000]\n",
    "\n",
    "print('Creating features')\n",
    "feature_sets = [(features(d), c) for (d, c) in documents]\n",
    "random.shuffle(feature_sets)\n",
    "\n",
    "print('Creating train/test sets')\n",
    "cutoff = math.ceil(len(feature_sets) * 0.7)\n",
    "train_set, test_set = feature_sets[:cutoff], feature_sets[cutoff:]\n",
    "'''\n",
    "feature_sets = [(bigram_features(d), c) for (d, c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_sets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 82.98%\n",
      "              |      e                                                  |\n",
      "              |      n                                                  |\n",
      "              |      t                                                  |\n",
      "              |      e                                         t        |\n",
      "              |      r                                         e        |\n",
      "              |      t                    p                    c        |\n",
      "              |      a                    o      s             h      w |\n",
      "              |      i                    l      c      s      n      e |\n",
      "              |      n             g      i      i      p      o      a |\n",
      "              |      m             a      t      e      o      l      t |\n",
      "              |      e      f      m      i      n      r      o      h |\n",
      "              |      n      u      e      c      c      t      g      e |\n",
      "              |      t      n      s      s      e      s      y      r |\n",
      "--------------+---------------------------------------------------------+\n",
      "entertainment | <12.8%>     .   2.1%      .      .      .      .      . |\n",
      "          fun |      . <10.6%>  4.3%      .      .      .      .      . |\n",
      "        games |      .      .  <4.3%>     .      .      .      .      . |\n",
      "     politics |      .      .      . <14.9%>     .      .      .      . |\n",
      "      science |      .      .   2.1%      . <14.9%>     .      .   2.1% |\n",
      "       sports |      .      .      .      .      . <12.8%>     .      . |\n",
      "   technology |      .      .   2.1%      .   4.3%      .  <6.4%>     . |\n",
      "      weather |      .      .      .      .      .      .      .  <6.4%>|\n",
      "--------------+---------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "NuSVC: 87.23%\n",
      "              |      e                                                  |\n",
      "              |      n                                                  |\n",
      "              |      t                                                  |\n",
      "              |      e                                         t        |\n",
      "              |      r                                         e        |\n",
      "              |      t                    p                    c        |\n",
      "              |      a                    o      s             h      w |\n",
      "              |      i                    l      c      s      n      e |\n",
      "              |      n             g      i      i      p      o      a |\n",
      "              |      m             a      t      e      o      l      t |\n",
      "              |      e      f      m      i      n      r      o      h |\n",
      "              |      n      u      e      c      c      t      g      e |\n",
      "              |      t      n      s      s      e      s      y      r |\n",
      "--------------+---------------------------------------------------------+\n",
      "entertainment | <10.6%>     .      .      .      .      .      .      . |\n",
      "          fun |      .  <8.5%>     .      .      .      .   2.1%      . |\n",
      "        games |      .      . <10.6%>     .      .      .      .      . |\n",
      "     politics |      .      .      . <14.9%>     .      .      .      . |\n",
      "      science |      .   2.1%      .      . <17.0%>     .      .      . |\n",
      "       sports |   2.1%      .      .      .      . <12.8%>     .      . |\n",
      "   technology |      .      .      .      .   2.1%      .  <4.3%>     . |\n",
      "      weather |      .      .   4.3%      .      .      .      .  <8.5%>|\n",
      "--------------+---------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "\n",
      "LogisticRegression: 91.49%\n",
      "              |      e                                                  |\n",
      "              |      n                                                  |\n",
      "              |      t                                                  |\n",
      "              |      e                                         t        |\n",
      "              |      r                                         e        |\n",
      "              |      t                    p                    c        |\n",
      "              |      a                    o      s             h      w |\n",
      "              |      i                    l      c      s      n      e |\n",
      "              |      n             g      i      i      p      o      a |\n",
      "              |      m             a      t      e      o      l      t |\n",
      "              |      e      f      m      i      n      r      o      h |\n",
      "              |      n      u      e      c      c      t      g      e |\n",
      "              |      t      n      s      s      e      s      y      r |\n",
      "--------------+---------------------------------------------------------+\n",
      "entertainment | <10.6%>     .      .      .      .      .      .      . |\n",
      "          fun |      .  <8.5%>     .      .      .      .   2.1%      . |\n",
      "        games |      .      . <14.9%>     .      .      .      .      . |\n",
      "     politics |      .      .      . <14.9%>     .      .      .      . |\n",
      "      science |      .   2.1%      .      . <17.0%>     .      .      . |\n",
      "       sports |   2.1%      .      .      .      . <12.8%>     .      . |\n",
      "   technology |      .      .      .      .   2.1%      .  <4.3%>     . |\n",
      "      weather |      .      .      .      .      .      .      .  <8.5%>|\n",
      "--------------+---------------------------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display(num):\n",
    "    return '{0:.2f}'.format(num)\n",
    "\n",
    "def run_classifier(name, classifier, train_set, test_set):\n",
    "    clf = SklearnClassifier(classifier)\n",
    "    clf.train(train_set)\n",
    "    \n",
    "    # general classifier accuracy\n",
    "    acc = accuracy(clf, test_set)\n",
    "    print('{}: {}%'.format(name, display(acc * 100)))\n",
    "    \n",
    "    # confusion matrix\n",
    "    gold = clf.classify_many([fs for (fs, l) in test_set])\n",
    "    test = [l for (fs, l) in test_set]\n",
    "    cm = nltk.ConfusionMatrix(gold, test)\n",
    "    print(cm.pretty_format(show_percents=True))\n",
    "\n",
    "# Naive Bayes\n",
    "run_classifier('Multinomial NB', MultinomialNB(), train_set, test_set)\n",
    "print()\n",
    "\n",
    "# SVM\n",
    "run_classifier('NuSVC', NuSVC(), train_set, test_set)\n",
    "print()\n",
    "\n",
    "# Logistic Regression\n",
    "run_classifier('LogisticRegression', LogisticRegression(), train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
