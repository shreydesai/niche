{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import itertools\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "parent = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "parent = parent.split('/')\n",
    "parent.remove(parent[-1])\n",
    "parent = '/'.join(parent)\n",
    "categories = ['entertainment', 'sports', 'fun', 'games', 'weather', 'science', 'technology', 'politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fileids(category):\n",
    "    path = os.path.join(parent, 'corpus', 'processed', category)\n",
    "    return os.listdir(path)\n",
    "\n",
    "def words(file):\n",
    "    f = open(file, 'r', encoding='ISO-8859-1').read().strip()\n",
    "    sents = [sent.split(' ') for sent in f.split('\\n')]\n",
    "    words = [word for sent in sents for word in sent if len(word) > 0]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 4110411\n"
     ]
    }
   ],
   "source": [
    "cfd = nltk.ConditionalFreqDist()\n",
    "\n",
    "documents, total_words = [], []\n",
    "\n",
    "for category in categories:\n",
    "    \n",
    "    for fileid in fileids(category):\n",
    "        if fileid == '.DS_Store':\n",
    "            continue\n",
    "        path = os.path.join(parent, 'corpus', 'processed',\n",
    "                            category, fileid)\n",
    "        \n",
    "        # for each category, increment the amount of times\n",
    "        # a single word appears in it\n",
    "        fileid_words = words(path)\n",
    "        \n",
    "        for word in fileid_words:\n",
    "            cfd[category][word] += 1 \n",
    "        \n",
    "        documents.append((fileid_words, category))\n",
    "        total_words.extend(fileid_words)\n",
    "\n",
    "fd = nltk.FreqDist([w.lower() for w in total_words])\n",
    "    \n",
    "print('Word count:', len(total_words))\n",
    "#random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment\n",
      "new 3085\n",
      "video 2165\n",
      "#oscars 1603\n",
      "says 1436\n",
      "star 1427\n",
      "watch 1371\n",
      "best 1302\n",
      "trump 1260\n",
      "first 1165\n",
      "see 1043\n",
      "\n",
      "games\n",
      "new 3083\n",
      "available 2007\n",
      "game 1926\n",
      "2 1696\n",
      "steam 1679\n",
      "games 1546\n",
      "get 1492\n",
      "#steamnewrelease 1455\n",
      "ps4 1342\n",
      "one 1339\n",
      "\n",
      "weather\n",
      "rain 4539\n",
      "warning 3824\n",
      "tornado 3636\n",
      "pm 2888\n",
      "weather 2851\n",
      "snow 2709\n",
      "day 2704\n",
      "cst 2668\n",
      "forecast 2398\n",
      "today 2389\n",
      "\n",
      "science\n",
      "new 3761\n",
      "science 2390\n",
      "scientists 1982\n",
      "via 1862\n",
      "could 1669\n",
      "may 1367\n",
      "us 1277\n",
      "space 1255\n",
      "first 1157\n",
      "one 1047\n",
      "\n",
      "sports\n",
      "game 1892\n",
      "win 1418\n",
      "new 1201\n",
      "team 1171\n",
      "vs 1129\n",
      "via 1105\n",
      "nfl 1097\n",
      "one 1081\n",
      "first 1076\n",
      "season 1070\n",
      "\n",
      "politics\n",
      "trump 9123\n",
      "says 3440\n",
      "trump's 2789\n",
      "brexit 2277\n",
      "president 2122\n",
      "new 2092\n",
      "donald 1993\n",
      "house 1975\n",
      "#hw 1680\n",
      "may 1616\n",
      "\n",
      "technology\n",
      "new 2941\n",
      "#cdntech 2448\n",
      "data 1827\n",
      "google 1722\n",
      "apple 1625\n",
      "tech 1450\n",
      "facebook 1266\n",
      "app 1126\n",
      "says 908\n",
      "big 849\n",
      "\n",
      "fun\n",
      "like 2683\n",
      "i'm 2225\n",
      "it's 2120\n",
      "people 1905\n",
      "green 1905\n",
      "don't 1749\n",
      "get 1603\n",
      "one 1567\n",
      "blue 1315\n",
      "u 1224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "for condition in cfd.conditions():\n",
    "    print(condition)\n",
    "    features = sorted(cfd[condition], key=lambda x: cfd[condition][x], reverse=True)\n",
    "    sig_features = [x for x in features if x not in stop]\n",
    "    \n",
    "    top_50 = sig_features[:10]\n",
    "    for item in top_50:\n",
    "        count = cfd[condition][item]\n",
    "        print('{} {}'.format(item, count))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_finder = BigramCollocationFinder.from_words(total_words)\n",
    "bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 5000)\n",
    "d = {bigram: True for bigram in bigrams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tia', 'mowry'),\n",
       " ('morning.northern', '#ny'),\n",
       " ('2(alice',\n",
       "  'experiment)-&gt;3-&gt;4-&gt;5(cms)-&gt;6-&gt;7-&gt;8(lhcb)-&gt;point1'),\n",
       " (\"@andersoncooper's\", 'ridiculist'),\n",
       " ('no.12', '@uvamenshoops'),\n",
       " ('pretentiously', \"hawai'i\"),\n",
       " ('jconnelly', 'nportman'),\n",
       " ('on-again', 'off-again'),\n",
       " ('jyaysi', 'desai'),\n",
       " ('tedxamsterdam', 'schiphol')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(d.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature size: 1617552\n"
     ]
    }
   ],
   "source": [
    "all_words = set(nltk.bigrams(total_words))\n",
    "word_features = [' '.join(x) for x in list(all_words)]\n",
    "#all_words = set(total_words)\n",
    "#word_features = list(all_words)\n",
    "random.shuffle(word_features)\n",
    "word_features = word_features[:2000]\n",
    "print('Feature size:', len(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "def bigram_features(words, score_fn=BigramAssocMeasures.chi_sq, n=2000):\n",
    "    bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "    bigrams = bigram_finder.nbest(score_fn, n)\n",
    "    return dict([(' '.join(ngram), True) for ngram in itertools.chain(words, bigrams)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = [documents[1], documents[2]]\n",
    "t = [(bigram_features(d), c) for (d, c) in d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8344 10281\n",
      "29290 30350\n",
      "['raddatz cooper', 'holocaust survivor', 's h o w i n g', 't h i n g', '@ e a t t h e w o r l d t v', 'u n d e n i a b l e', 'gretchen carlson', 'a l l e g e d', 'a n d e r s o n', 'n o v e l i s t s', \"cookie's wardrobe\", '# s o m e t h i n g r o t t e n', 't a l e s', 't h e a t r i c a l', '# t h e n i g h t o f', 'h o l d s', 'g o s p e l', 'u n u s u a l', 'g r e a t', '# b i r b i g l i a', 'b u i l d s', 'v o t e', 'e m b a r r a s s e d', 's l a y', '# r o n g o l d m a n', '# l i n - m a n u e l', '@ j l o', '# m a n b o o k e r p r i z e', 'l i v e - a c t i o n', 'i n v o l v e', 'cry @5xpaz', 'r e c o v e r y', '8 . 8 m', 'f i f t y', 't w o', '# c u r i o u s g e o r g e', 'w e a p o n', 'f a t a l', 'fiennes richard', '# m a c k l e m o r e', '# n a s', 'r u p t u r e', 'r i s i n g', '# z e n d a y a', '@susansarandon @mrdannyglover', '@ j o h n c e n a', 'c d', '@5xpaz #nickcannon', 'l i k e s', 'n a w l i n s']\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(t[0][0]), len(t[1][0]))\n",
    "print(len(documents[1][0]), len(documents[2][0]))\n",
    "\n",
    "print(list(t[1][0].keys())[:50])\n",
    "print(t[1][0]['raddatz cooper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 163\n"
     ]
    }
   ],
   "source": [
    "feature_sets = [(bigram_features(d), c) for (d, c) in documents]\n",
    "random.shuffle(feature_sets)\n",
    "print('Documents:', len(feature_sets))\n",
    "cutoff = math.ceil(len(feature_sets) * 0.7)\n",
    "train_set, test_set = feature_sets[:cutoff], feature_sets[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "entertainment 17\n",
      "games 13\n",
      "science 12\n",
      "fun 16\n",
      "sports 13\n",
      "weather 13\n",
      "politics 16\n",
      "technology 15\n",
      "\n",
      "Test Set\n",
      "technology 5\n",
      "politics 4\n",
      "games 8\n",
      "science 8\n",
      "fun 5\n",
      "weather 6\n",
      "entertainment 4\n",
      "sports 8\n"
     ]
    }
   ],
   "source": [
    "print('Training Set')\n",
    "training_counts = [y for (x, y) in train_set]\n",
    "for k, v in collections.Counter(training_counts).items():\n",
    "    print(k, v)\n",
    "print()\n",
    "print('Test Set')\n",
    "test_counts = [y for (x, y) in test_set]\n",
    "for k, v in collections.Counter(test_counts).items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def display(num):\n",
    "    return '{0:.2f}'.format(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB: 81.25%\n",
      "NuSVC: 93.75%\n",
      "LogisticRegression: 93.75%\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import accuracy\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = SklearnClassifier(MultinomialNB())\n",
    "classifier.train(train_set)\n",
    "acc = accuracy(classifier, test_set)\n",
    "print('Multinomial NB: {}%'.format(display(acc * 100)))\n",
    "\n",
    "classifier = SklearnClassifier(NuSVC())\n",
    "classifier.train(train_set)\n",
    "acc = accuracy(classifier, test_set)\n",
    "print('NuSVC: {}%'.format(display(acc * 100)))\n",
    "\n",
    "classifier = SklearnClassifier(LogisticRegression())\n",
    "classifier.train(train_set)\n",
    "print('LogisticRegression: {}%'.format(display(acc * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: sports\n",
      "science 0.120813609397\n",
      "weather 0.121269114468\n",
      "politics 0.120959745752\n",
      "entertainment 0.13126598441\n",
      "games 0.121839852946\n",
      "technology 0.120982251026\n",
      "sports 0.13149354798\n",
      "fun 0.131375894022\n"
     ]
    }
   ],
   "source": [
    "probs = classifier.prob_classify(features(\"take a look at the latest wind chills mostly teens in the city don't forget the hat scarf and gloves today\".split(' ')))\n",
    "print('max:', probs.max())\n",
    "for sample in probs.samples():\n",
    "    print(sample, probs.prob(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
